# Setting up the database

- Install postgres
- Create a database named 'sociallists'
- In python, do:

  >>> from sociallists import db
  >>> db.Base.metadata.create_all()

# TODO:

- On the add feed flow, do the following:
  1. Automatically refresh feed for the first time if no refresh has been done
  2. When doing first-feed-update, remove all but the top two or three items
     from the first update, so that your feed is not destroyed by 20 or 30 items
  (How does this work when feed updating is shared? Maybe the top-three thing
  should be a general feature, and we should suppress more than three feeds
  per update in the UI? (Maybe with a more... link))
- On the add feed flow add autodiscovery and redirect chasing before adding
  to the DB
- Use BeautifulSoup to extract thumbnails
- Extract enclosures and the like
- Re-visit use of requirements and packages and vendoring and the like
- Put river items in the DB so that we can efficiently re-run the processing
  steps for items that are out of the feed
- For the future, we'll probably need options on individual feeds for
  processing to make them better. It is possible to over-engineer this so be
  careful.
- Implement ATOM cache timeout and RSS skip hours and the like to poll more
  intelligently.
- Implement pubsubhubbub
