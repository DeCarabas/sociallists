# Setting up the database

- Install postgres
- Create a database named 'sociallists'
- In python, do:

  >>> from sociallists import db
  >>> db.Base.metadata.create_all()

# Some notes on asynchrony

I spent some time trying to convert this codebase to asyncio so that feed
updates can be SUPER PARALLEL. What I discovered is that if I do this the HTTP
stack begins to misbehave and timeout and stuff, and I'm not entirely sure why.

So aiohttp doesn't seem to be a good choice for me.

Using coroutines but a fundamentally blocking HTTP stack (asyncio + requests)
doesn't actually buy me anything because all my threads will be blocked on the
same fixed number of HTTP requests anyway, so it will be a lot of complexity
for absolutely no efficiency gain.

(In addition, the async/await stuff is currently very ugly and the docs are
complicated and I just like this one better for now. So we're sticking with
the slow but useful. Rewriting the feed update process to be massively parallel
is still something I want to do but it will have to wait.)

# TODO:

UI:
- Error boxes
- Enable jumping between refresh sessions:
  - Mark the top refresh session on all rivers when we start a refresh.
  - Put navigation buttons in the boundaries between refreshes that jump up
    and down. (i.e., build a meta-FeedUpdate construct that is "refresh
    session"; it will be river-specific. This might be complex.)
- Add/remove rivers
- Add/remove feeds from rivers
- Add/remove river sets
- Re-order rivers

Shipping:
- Re-visit use of requirements and packages and vendoring and the like
- Re-pack font awesome fonts
- Use packed/minified/precompiled source if it exists

Feed Stuff:
- Extract enclosures and the like, store locally (in the DB) and present them
  in the river. (Then do UI work to expose audio enclosures and the like.)
- Put river items in the DB so that we can efficiently re-run the processing
  steps for items that are out of the feed
- For the future, we'll probably need options on individual feeds for
  processing to make them better. It is possible to over-engineer this so be
  careful.
- Implement ATOM cache timeout and RSS skip hours and the like to poll more
  intelligently.
- Implement pubsubhubbub
- Convert to sqlite as part of moving to a self-contained app
  - Alternately, provide a compat layer for sqllite. Maybe SQLAlchemy already
    gives me everything I need?
- Fix Syblmoon bug where no title means broken rendering
- Clip titles that are too long. (Because seriously.)
- b0rk's feed refreshes completely every time there's a new article; fix it!
